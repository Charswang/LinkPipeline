使用LSTM来预测压缩算法的选择；

**只考虑了怎样使压缩空间减少，没有考虑算法运行时间、查询性能降低等因素，并没有对数据进行分类**

---

使用先前块的压缩比来预测使用特定压缩算法的块的压缩比？？什么意思；

压缩的数据所采用的压缩比与直接输入的实际数据有关系，所以很难预先预测压缩比；

从每个数据块中提取特征；

---

**找到相似的数据块：**要压缩的数据块作为输入，然后自动提取这些块中的特征，并且计算找到与他相似的块；

**对数据块使用压缩算法**：然后**对这些相似的块使用相同的压缩算法；**

---

数据库中的压缩算法：**轻量级压缩算法【速度快，压缩率低】和重量级算法【速度低、压缩率高】**

##### 轻量级压缩算法

>  通过注意**连续值之间的关系**对数据进行压缩；通过使用上下文知识【**数据的局部性和值的分布**】用较短的数据替换较长的数据来进行压缩；

**零位抑制（NS）、参考帧（FOR）、增量编码（delta）、游程长度编码（RLE）、字典压缩（DICT）和位向量（BV）**【null suppression  (NS),  frame-of-reference  (FOR), delta encoding (DELTA), run-length encoding (RLE), dictionary compression (DICT) and bit vectors (BV)】

**NS**：省略每个值中的前导零，对于小整数很有效【比如1这个数字存储的时候是8位来存储的，所以可以将前导零省略】

**FOR**：将每个值表示为某个值的差值，该值通常是序列的第一个值或平均值

**DELTA**：表示每个值与其前一个值之间的差值

**RLE**：游程编码

**DICT**：维护一个包含所有不同值的字典，并用字典给出的键替换每个值。

**BV**：用位向量表示每个不同的值。

##### 重量级压缩算法

**Huffman coding**, **Rice coding** and **LZ **

---

许多压缩算法都会依赖上下文

**每个压缩算法都有自己的特点，不同的数据特征有其对应的最优的压缩算法；**

#### Implement

<font color="red">采用**深度学习方法来自动学习有用的特征，而不是手工从原始数据块中定义特征以选择压缩算法???**</font><font color="light blue">**怎么自动学习的，为什么就不用手动选择了？？**</font>[16]。具体来说，由于长-短记忆网络具有很强的探索序列数据之间关系的能力，因此使用了长-短记忆网络。

##### 模型

> 有时候，一个特殊的算法可能只用于压缩记录较少的列；或者只压缩一个列的有限范围的记录；

首先通过数据预处理把原始数据集转换成块向量和块标签对；

然后将块向量和快标签分成几批，每一批中包括了多个支持向量[每一批中的支持向量应该是一样的]和单个查询向量【**<font color="orange">这里我有个问题：第一个是他是怎样事先得到那些块的最佳压缩算法的【事先手动搞得？】，第二个就是他是怎么把查询向量和多个支持向量分出来的？？【直接分的训练集和测试集？】</font>**】，作为LSTM的输入，然后利用LSTM网络**生成特征向量**，最后利用特征向量计算查询特征向量和支持特征向量之间的**距离**，预测查询数据的压缩类别。【选择与查询向量的相似度最大的支持向量的压缩算法。】

？？？？？

LSTM中的**支持向量**和**查询向量**分别是训练集和测试集；【支持向量是每个压缩算法中的最具代表性的数据块；】
