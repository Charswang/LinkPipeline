## 研究内容梳理与开题意义研究

> **面向数据温度和负载的自适应(/弹性)存储优化研究**

### 研究问题的来源

大数据时代中的数据在急剧增长，某某机构说到每年增长数据量有多少多少。存储这些大量数据会耗费很多存储空间。对于这些数据的存储需要考虑到存储成本和能耗问题；

**1、**为了缓解数据存储成本和能耗问题，有许多方式可以减少数据的存储占用(重复数据删除/数据压缩等方式)。其中数据压缩能够有效减少数据的存储占用，【数据压缩虽然可以减少存储占用，但是减少空间的代价就是额外的cpu消耗，会造成访问性能的部分下降；但是有些场景下是乐意那访问性能来换取存储空间的减少的；】   每种文件和数据类型所适合的最佳压缩算法也是不同的；但是如果一直使用固定压缩算法是不可取的；在不同的负载情况和访问模式下，对数据的压缩需要有着不同的压缩要求。**这就需要根据不同的情况来对数据的压缩与否和压缩效果做决策；**需要从多方面考虑：数据需不需要压缩、若需要压缩，又要选择那种压缩算法既不影响总体的系统性能，又能有效减少存储空间。【**目前的一些研究：**】以往学者使用压缩来解决存储空间占用大的问题的时候通常**<font color="red">只专注于减少存储占用，没有考虑数据访问模式的动态改变的情况，不能有效的根据访问模式的改变来调整压缩算法，甚至对总体系统的性能影响过大；</font>**根据以上问题：提出一种根据冷热数据以及工作负载情况来对不同数据的压缩算法进行弹性调整的策略。与使用固定压缩算法相比可以有效地在系统性能和存储空间占用上做到很好的权衡；【**怎样的策略：**】；**<font color="red">其实就是担心只有这一个点，做出来的东西不尽人意，工作量少，不能满足毕业要求。但是吧，如果加上下面自适应数据迁移的点，有感觉太多，又做不完；并且也没有idea。。。</font>**

**2、**另外考虑到存储成本问题，通常会根据数据温度来把不同温度的数据分别放到性能高的SSD以及性能较差但是成本较低的HDD【对象存储】上。但是在混合存储上缺乏一种能够动态根据数据访问情况和类型来自适应调整数据的存放介质的策略；【**目前的一些研究**】【**自己提出的研究**】----还没咋看过混合存储的部分，不知道有什么可以创新的？提出一种根据数据温度和负载情况的自适应分级存储策略；

### 研究的目的和意义

在急剧增长的数据量的背景下，通过自适应压缩存储与数据布局来有效的减少数据存储空间；与默认固定压缩相比能够有效提升系统总体性能；避免工业上需要业务人员根据经验并手动对不同种类的数据存储形式进行调整的缺点；

### 应用价值

能够有效减少存储占用量，与固定压缩和默认数据方式相比，能够有效提升存储性能；

### 创新点

以往学者使用压缩来解决存储空间占用大的问题的时候通常只专注于减少存储占用，没有考虑数据访问模式的动态改变的情况，不能有效的根据访问模式的改变来调整压缩算法，甚至对总体系统的性能影响过大；

### 国内外研究现状



### 自己想课题的可行性

压缩这个应该和自适应迁移类似的

其实自适应数据迁移也是可以是由业务人员设置固定时间把数据定时迁移；压缩这样的其实也是可以让业务人员自定义冷数据时间，然后把冷数据使用固定压缩算法进行压缩；

这里延伸的方向就是：怎样预估最适合数据的压缩算法；怎么去根据数据温度在各种压缩算法中选出最合适的压缩算法；怎么控制压缩算法的更换时机；**以上的评价指标：在zipf下的访问量下，看和固定压缩算法的方式相比：不同数据量下和不同的访问量下，总体访问时间和这一阶段访问结束后总体占用的空间；**怎样根据未来的访问负载情况和资源利用情况来动态调整压缩算法；--**动态负载调整的评价指标：**

**根据未来的访问负载情况和资源利用情况来动态调整压缩算法的可行性：**三种状态：1、访问频度的高低；2、cpu使用高低；3、IO占用的高低；**问题：**1、cpu如果在很繁忙的程度下/访问频度很高的情况下，查询的速度肯定是会有所下降，能不能就是把下个阶段可能会被访问的数据变成更轻一点的压缩或者不压缩；来提升下查询性能；2、如果在io较高的情况下为了缓解io，是不是可以把部分较轻的压缩转为较重的压缩来缓解io，代价是查询时间可能会增加一些，或者就是结合io的繁忙程度，看在原来压缩下在io上花的时间，能不能由更重的压缩减少io上的时间和在查询上增加的时间抵消掉。。。三种情况分别结合的情况呢？；

## 期望要达到的效果，-- 每个问题的评估性能指标

第一个：压缩预估，冷温热数据的分配和更换时机问题；

> 因为和未压缩的情况相比的话，查询时间肯定是会增加很多的，但是同时存储空间也会减少很多；目前认为还是和使用默认固定压缩算法相比吧；目标：在两方面：这一阶段的**查询时间和存储空间都有所提升**

第二个：工作负载动态更换压缩的问题

> 期望的效果：？？？



哎，看起来就感觉没啥东西，并且自己又做不出来效果。。。



> 下面算是目前总结和遇到的问题梳理；总结汇报；2个小时

## 目前进展梳理

步骤：

预估压缩算法的压缩率、压缩时间、解压缩时间是直接对整个文件进行测试的；-- 还没有用上压缩时间、文件大小、文件关联性；

①、***冷温热双队列识别方式***

②、***冷温热数据的压缩算法分配方式***-- 目前是将压缩率、解压缩速度归一化，然后恩据数据温度分权重然后求和，分别得到该文件每个压缩算法的分数。【需要重新考虑。不能像之前那样--[冷数据使用最重的压缩算法1:0，温数据使用1:1，热数据就不压缩0:1\]】--**自适应权重【觉着可以考虑一下】**；

③、***冷温热数据压缩算法的动态更换--两个更换条件。***

目前算是快做完**<1>更换条件1**了：1、转热的更换条件是：访问频率*更换压缩算法减少的查询时间是否>更换压缩算法所消耗的时间；2、但是转冷的更换条件还没弄好--现在想的是距离上次访问的时间>(假设10)的搞成xx，距离上次访问的时间>(假设500)的搞成最中重的压缩；-- **转冷的方式【目前是手动设置阈值，有没有好点的方式？？？】**

**<2>更换条件二**：与当时的的负载情况有关，如果负载超过占用的80%，先将转热的数据做为优先级任务，把转冷的数据作为低优先级任务；【前面这个肯定是可以的】；同时也不能一定说是把所有转热的数据都完成，比如，转热的数据在转热之后的利益要大于X才能进行转换压缩算法；



直到2021-12-11为止，分别使用300文件3000次访问、300文件10000次访问和500文件(同一个文件复制了500份)10000次访问。

由于转冷的设置，是手动看距离上次访问有多久没有被访问才转冷的，是有一些不行。

但是在加了更换条件1之后，前两种访问中HEC的访问时间可以为使用压缩算法中最小的，但是与lz4比总访问时间减少的不太多。但是访问完之后的总共占用空间HEC的占用却比lz4还要高。。但是换成500文件10000次访问之后，HEC的访问时间在使用压缩算法中的方式中最少，然后最后的总占用空间是要比lz4要小的；

## 目前问题以及待解决问题

虽然在500文件和10000次访问上在查询和存储上比固定压缩算法是要好些，但是好的只有一点，效果并不大；

**转冷数据的更换条件要怎么更改一下？**

**怎样根据线性的数据温度来自适应分配冷温热数据的压缩算法**

**冷热识别感觉想改一下--改成线性，然后加上文件大小【肯定回影响到压缩算法的选择，文件很大的话，变成热数据的时候，不一定必须变成不压缩的状态吧？】和文件关联性的因素；**

**怎样根据负载情况设置更换条件二**

---

数据块的压缩更换没有搞定，现在就是在用文件粒度在做实验；我觉着虽然压缩粒度不一样，但是大致思路都差不多，所以就先做了；

